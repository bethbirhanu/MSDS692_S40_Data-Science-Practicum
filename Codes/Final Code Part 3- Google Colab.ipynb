{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc44b63",
   "metadata": {},
   "source": [
    "# Continuing from 'Final Code Part 2', Further Analysis and Actions Below "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf3cb5d",
   "metadata": {},
   "source": [
    "# ............."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be35acd2",
   "metadata": {
    "id": "be35acd2"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e859a8",
   "metadata": {
    "id": "75e859a8"
   },
   "source": [
    "### Step 1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5c55f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7799,
     "status": "ok",
     "timestamp": 1709757227474,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "6aa5c55f",
    "outputId": "f0219dc0-f560-4707-d84b-76d791de6f1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "<ipython-input-30-05b14f666560>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emails_cleaned['tokenized_body'] = df_emails_cleaned['filtered_body'].apply(tokenize_sentence)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for tokenization\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to tokenize a sentence\n",
    "def tokenize_sentence(sentence):\n",
    "    tokens = word_tokenize(str(sentence))  # Tokenize the sentence into words\n",
    "    return tokens\n",
    "\n",
    "# Apply tokenization to the 'filtered_body' column\n",
    "df_emails_cleaned['tokenized_body'] = df_emails_cleaned['filtered_body'].apply(tokenize_sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b04751e",
   "metadata": {
    "id": "0b04751e"
   },
   "source": [
    "#### Step 2: Adding a special Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1804436",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1709757234105,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "c1804436",
    "outputId": "ea9dbb0e-4b70-4817-b715-ff0a1f8e030d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-bb9511decbfb>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emails_cleaned['body_with_special_tokens'] = df_emails_cleaned['tokenized_body'].apply(add_special_tokens)\n"
     ]
    }
   ],
   "source": [
    "# Function to add special tokens <start> and <end> to a list of tokens\n",
    "def add_special_tokens(tokens):\n",
    "    tokens_with_special_tokens = ['<start>'] + tokens + ['<end>']\n",
    "    return tokens_with_special_tokens\n",
    "\n",
    "# Apply adding special tokens to the 'tokenized_body' column\n",
    "df_emails_cleaned['body_with_special_tokens'] = df_emails_cleaned['tokenized_body'].apply(add_special_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75055da2",
   "metadata": {
    "id": "75055da2"
   },
   "source": [
    "#### Step 3: Constructing Sequence Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c7553e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1709757244400,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "f5c7553e",
    "outputId": "0169f3f9-3651-4e2f-c1ce-642a15f0045d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-d6c7dc149a70>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_emails_cleaned['sequence_pairs'] = df_emails_cleaned['body_with_special_tokens'].apply(create_sequence_pairs)\n"
     ]
    }
   ],
   "source": [
    "# Function to split a list of tokens into pairs of input and output sequences\n",
    "def create_sequence_pairs(tokens):\n",
    "    sequence_pairs = []\n",
    "    for i in range(1, len(tokens)):\n",
    "        input_sequence = tokens[:i]  # Input sequence from start to current token\n",
    "        output_sequence = tokens[i:]  # Output sequence from current token to end\n",
    "        sequence_pairs.append((input_sequence, output_sequence))\n",
    "    return sequence_pairs\n",
    "\n",
    "# Apply sequence pair creation to the 'body_with_special_tokens' column\n",
    "df_emails_cleaned['sequence_pairs'] = df_emails_cleaned['body_with_special_tokens'].apply(create_sequence_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0415926",
   "metadata": {
    "id": "c0415926"
   },
   "source": [
    "Here's a breakdown of the feature engineering steps I performed:\n",
    "\n",
    "Tokenization: I tokenize the sentences in the 'filtered_body' column into lists of tokens (words or subwords). This step converts raw text into a format that can be processed by machine learning algorithms.\n",
    "\n",
    "Adding Special Tokens: I add special tokens <start> and <end> to each list of tokens in the 'tokenized_body' column. These tokens help the model learn the beginning and end of sequences during training.\n",
    "\n",
    "Constructing Sequence Pairs: I create pairs of sequences by splitting each tokenized sentence into multiple parts. Each pair consists of an input sequence and its corresponding output sequence. This step prepares the data for training a sequence-to-sequence model, where the model learns to predict an output sequence given an input sequence.\n",
    "\n",
    "These feature engineering steps are essential for building a sequence-to-sequence model that can effectively learn from text data and generate meaningful outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34954cd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1709757251524,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "34954cd7",
    "outputId": "3889fd7b-c6c6-4b2e-f415-3339b305b4dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sequence pairs: 902983\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of sequence pairs\n",
    "total_pairs = df_emails_cleaned['sequence_pairs'].apply(len).sum()\n",
    "\n",
    "print(\"Total number of sequence pairs:\", total_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abea2da",
   "metadata": {
    "id": "jTKumyAFYs8Y"
   },
   "source": [
    "#### Loading the Cleaned email ('emails_cleaned') and checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vYc90qZdYs_U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24651,
     "status": "ok",
     "timestamp": 1709755916847,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "vYc90qZdYs_U",
    "outputId": "2ace9872-1860-4480-c9c5-b115e60e7176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "                       file  \\\n",
      "0     allen-p/_sent_mail/1.   \n",
      "1   allen-p/_sent_mail/100.   \n",
      "2  allen-p/_sent_mail/1001.   \n",
      "3  allen-p/_sent_mail/1002.   \n",
      "4  allen-p/_sent_mail/1004.   \n",
      "\n",
      "                                             message  \\\n",
      "0  Message-ID: <18782981.1075855378110.JavaMail.e...   \n",
      "1  Message-ID: <24216240.1075855687451.JavaMail.e...   \n",
      "2  Message-ID: <30922949.1075863688243.JavaMail.e...   \n",
      "3  Message-ID: <30965995.1075863688265.JavaMail.e...   \n",
      "4  Message-ID: <17189699.1075863688308.JavaMail.e...   \n",
      "\n",
      "                                                body  \\\n",
      "0                          Here is our forecast\\n\\n    \n",
      "1                     test successful.  way to go!!!   \n",
      "2                Let's shoot for Tuesday at 11:45.     \n",
      "3  Greg,\\n\\n How about either next Tuesday or Thu...   \n",
      "4                   any morning between 10 and 11:30   \n",
      "\n",
      "                                        cleaned_body  cleaned_message_length  \\\n",
      "0                               here is our forecast                      20   \n",
      "1                          test successful way to go                      25   \n",
      "2                     lets shoot for tuesday at 1145                      30   \n",
      "3  greg how about either next tuesday or thursday...                      54   \n",
      "4                    any morning between 10 and 1130                      31   \n",
      "\n",
      "                                      processed_body  \\\n",
      "0                           ['here is our forecast']   \n",
      "1                      ['test successful way to go']   \n",
      "2                 ['lets shoot for tuesday at 1145']   \n",
      "3  ['greg how about either next tuesday or thursd...   \n",
      "4                ['any morning between 10 and 1130']   \n",
      "\n",
      "                                       filtered_body  \\\n",
      "0                           ['here is our forecast']   \n",
      "1                      ['test successful way to go']   \n",
      "2                 ['lets shoot for tuesday at 1145']   \n",
      "3  ['greg how about either next tuesday or thursd...   \n",
      "4                ['any morning between 10 and 1130']   \n",
      "\n",
      "                                      tokenized_body  \\\n",
      "0  ['[', \"'here\", 'is', 'our', 'forecast', \"'\", ']']   \n",
      "1  ['[', \"'test\", 'successful', 'way', 'to', 'go'...   \n",
      "2  ['[', \"'lets\", 'shoot', 'for', 'tuesday', 'at'...   \n",
      "3  ['[', \"'greg\", 'how', 'about', 'either', 'next...   \n",
      "4  ['[', \"'any\", 'morning', 'between', '10', 'and...   \n",
      "\n",
      "                            body_with_special_tokens  \\\n",
      "0  ['<start>', '[', \"'here\", 'is', 'our', 'foreca...   \n",
      "1  ['<start>', '[', \"'test\", 'successful', 'way',...   \n",
      "2  ['<start>', '[', \"'lets\", 'shoot', 'for', 'tue...   \n",
      "3  ['<start>', '[', \"'greg\", 'how', 'about', 'eit...   \n",
      "4  ['<start>', '[', \"'any\", 'morning', 'between',...   \n",
      "\n",
      "                                      sequence_pairs  \n",
      "0  [(['<start>'], ['[', \"'here\", 'is', 'our', 'fo...  \n",
      "1  [(['<start>'], ['[', \"'test\", 'successful', 'w...  \n",
      "2  [(['<start>'], ['[', \"'lets\", 'shoot', 'for', ...  \n",
      "3  [(['<start>'], ['[', \"'greg\", 'how', 'about', ...  \n",
      "4  [(['<start>'], ['[', \"'any\", 'morning', 'betwe...  \n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Full path to the CSV file\n",
    "data_path = '/content/drive/My Drive/emails_cleaned.csv'\n",
    "\n",
    "# Load the CSV file\n",
    "df_emails_cleaned = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows to confirm it's loaded correctly\n",
    "print(df_emails_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90258924",
   "metadata": {
    "id": "90258924"
   },
   "source": [
    "###  Prepare Data for the Model\n",
    "After preprocessing and cleaning my data, I'll need to convert the texts into sequences that the model can learn from. This involves tokenization and creating input-target pairs.\n",
    "\n",
    "#### Tokenization and Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9dd70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22616,
     "status": "ok",
     "timestamp": 1709757306631,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "9af9dd70",
    "outputId": "2682fb5e-3051-4c78-cc31-b82f519b641b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input sequences: (902983, 31)\n",
      "Shape of output sequences: (902983, 31)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Extract sequence pairs from the DataFrame\n",
    "sequence_pairs = df_emails_cleaned['sequence_pairs'].tolist()\n",
    "\n",
    "# Flatten sequence pairs to a single list\n",
    "flattened_sequence_pairs = [pair for sublist in sequence_pairs for pair in sublist]\n",
    "\n",
    "# Extract input and output sequences from the flattened list of pairs\n",
    "input_sequences, output_sequences = zip(*flattened_sequence_pairs)\n",
    "\n",
    "# Initialize the tokenizer with a vocabulary size of 10k\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "\n",
    "# Fit tokenizer on input and output sequences\n",
    "tokenizer.fit_on_texts(input_sequences)\n",
    "tokenizer.fit_on_texts(output_sequences)\n",
    "\n",
    "# Convert text sequences to integer sequences\n",
    "input_sequences_int = tokenizer.texts_to_sequences(input_sequences)\n",
    "output_sequences_int = tokenizer.texts_to_sequences(output_sequences)\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "max_sequence_length = max([len(seq) for seq in input_sequences_int + output_sequences_int])\n",
    "input_sequences_padded = pad_sequences(input_sequences_int, maxlen=max_sequence_length, padding='post')\n",
    "output_sequences_padded = pad_sequences(output_sequences_int, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Shuffle the sequences\n",
    "indices = np.arange(len(input_sequences_padded))\n",
    "np.random.shuffle(indices)\n",
    "input_sequences_padded_shuffled = input_sequences_padded[indices]\n",
    "output_sequences_padded_shuffled = output_sequences_padded[indices]\n",
    "\n",
    "# Verify the shape of the padded sequences\n",
    "print(\"Shape of input sequences:\", input_sequences_padded_shuffled.shape)\n",
    "print(\"Shape of output sequences:\", output_sequences_padded_shuffled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424c5f0",
   "metadata": {
    "id": "b424c5f0"
   },
   "source": [
    "Explanation of the steps:\n",
    "\n",
    "- I extract the sequence pairs from the DataFrame and flatten them into a single list.\n",
    "- I separate input and output sequences from the flattened list of pairs.\n",
    "- I initialize the Keras Tokenizer with a vocabulary size of 10k and fit it on both input and output sequences.\n",
    "- I convert the text sequences to integer sequences using the tokenizer.\n",
    "- I pad the sequences to have the same length using the maximum sequence length found in the data.\n",
    "- I shuffle the sequences using numpy.\n",
    "- Finally, I print out the shape of the padded sequences to verify their dimensions.\n",
    "- This process prepares the tokenized, padded, and shuffled sequences for training the neural model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a924c9a5",
   "metadata": {
    "id": "a924c9a5"
   },
   "source": [
    "### Sequence to Sequence Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb343c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2691,
     "status": "ok",
     "timestamp": 1709757322121,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "f5cb343c",
    "outputId": "b9398c4e-18c9-42fd-a347-0c3217ad61b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 31)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 31)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 31, 256)              8398336   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 31, 256)              8398336   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 256),                525312    ['embedding[0][0]']           \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, 31, 256),            525312    ['embedding_1[0][0]',         \n",
      "                              (None, 256),                           'lstm[0][1]',                \n",
      "                              (None, 256)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 31, 32806)            8431142   ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26278438 (100.24 MB)\n",
      "Trainable params: 26278438 (100.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "\n",
    "# Define the input sequence shape\n",
    "input_shape = input_sequences_padded_shuffled.shape[1]\n",
    "\n",
    "# Define the vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Add 1 for the zero-padding token\n",
    "\n",
    "# Define the dimensionality of the embedding space\n",
    "embedding_dim = 256\n",
    "\n",
    "# Define the encoder\n",
    "encoder_inputs = Input(shape=(input_shape,))\n",
    "encoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder\n",
    "decoder_inputs = Input(shape=(input_shape,))\n",
    "decoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e02db",
   "metadata": {},
   "source": [
    "What I did on the above is:\n",
    "\n",
    "**Input Sequence Shape:** The shape of the input sequences, which is determined by the length of the input sequences after padding.\n",
    "\n",
    "**Vocabulary Size:** The size of the vocabulary, which is determined by the number of unique words in the tokenized text plus one for zero-padding.\n",
    "\n",
    "**Embedding Dimension:** The dimensionality of the embedding space for word representations.\n",
    "\n",
    "**Encoder:** Accepts input sequences and processes them using an embedding layer followed by an LSTM layer.\n",
    "The LSTM layer returns the final hidden state and cell state, representing the encoder's output.\n",
    "\n",
    "**Decoder:** Accepts target sequences and processes them using an embedding layer followed by an LSTM layer.\n",
    "The LSTM layer is configured to return sequences, allowing for sequence generation.\n",
    "The decoder's initial state is set to the final hidden and cell states of the encoder.\n",
    "\n",
    "**Dense Layer:** I used dense layer with softmax activation is to output the predicted probabilities for each word in the vocabulary.\n",
    "\n",
    "**Model Compilation:** The model is compiled using the RMSprop optimizer and sparse categorical cross-entropy loss, suitable for multi-class classification problems.\n",
    "\n",
    "**Model Summary:** The summary of the model architecture, including layer types, output shapes, and total parameters is printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2454b4",
   "metadata": {
    "id": "1a2454b4"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d11852",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2715317,
     "status": "ok",
     "timestamp": 1709760040951,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "63d11852",
    "outputId": "b7291eda-3a3b-4f04-9b7a-5d046482ffb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11288/11288 [==============================] - 290s 25ms/step - loss: 0.7624 - val_loss: 0.4815\n",
      "Epoch 2/10\n",
      "11288/11288 [==============================] - 270s 24ms/step - loss: 0.3966 - val_loss: 0.3296\n",
      "Epoch 3/10\n",
      "11288/11288 [==============================] - 270s 24ms/step - loss: 0.2867 - val_loss: 0.2476\n",
      "Epoch 4/10\n",
      "11288/11288 [==============================] - 269s 24ms/step - loss: 0.2172 - val_loss: 0.1893\n",
      "Epoch 5/10\n",
      "11288/11288 [==============================] - 269s 24ms/step - loss: 0.1655 - val_loss: 0.1455\n",
      "Epoch 6/10\n",
      "11288/11288 [==============================] - 270s 24ms/step - loss: 0.1270 - val_loss: 0.1127\n",
      "Epoch 7/10\n",
      "11288/11288 [==============================] - 269s 24ms/step - loss: 0.0973 - val_loss: 0.0861\n",
      "Epoch 8/10\n",
      "11288/11288 [==============================] - 270s 24ms/step - loss: 0.0739 - val_loss: 0.0659\n",
      "Epoch 9/10\n",
      "11288/11288 [==============================] - 269s 24ms/step - loss: 0.0563 - val_loss: 0.0509\n",
      "Epoch 10/10\n",
      "11288/11288 [==============================] - 268s 24ms/step - loss: 0.0432 - val_loss: 0.0398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7aa3f814f550>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit([input_sequences_padded_shuffled, output_sequences_padded_shuffled],\n",
    "          output_sequences_padded_shuffled,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82491eda",
   "metadata": {},
   "source": [
    "I trained the model using the 'fit' function, which takes input sequences and their corresponding output sequences as training data, specifying a batch size of 64 and training for 10 epochs. Also, a validation split of 20% was used to monitor the model's performance on unseen data during training.\n",
    "\n",
    "During training, the model's loss progressively decreased across epochs, indicating improvement in its ability to predict output sequences given input sequences. The validation loss also decreased, suggesting that the model generalizes well to unseen data. This trend suggests that the model is effectively learning the underlying patterns in the data and improving its performance over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87811068",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a6fa1",
   "metadata": {},
   "source": [
    "I use plot to visualize the model's learning progress and identifying any potential issues such as overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd3f623",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1709760617696,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "0cd3f623",
    "outputId": "b724952b-19d2-4a30-94fa-3991812aad11"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the training and validation loss from the model history\n",
    "training_loss = model.history.history['loss']\n",
    "validation_loss = model.history.history['val_loss']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a94cd",
   "metadata": {},
   "source": [
    "The graph displays the training and validation loss, both showing a consistent downward trend, indicating effective learning without overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0689848",
   "metadata": {},
   "source": [
    "### Saving my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5e0dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 877,
     "status": "ok",
     "timestamp": 1709760284628,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "40a5e0dc",
    "outputId": "f712b23c-222f-41b2-9d52-2836ea61100e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Defining the path\n",
    "model_path = '/content/drive/My Drive/trained_model.h5'\n",
    "\n",
    "# Save the trained model \n",
    "model.save(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e6584",
   "metadata": {},
   "source": [
    "### More Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yooovwdos0Zd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218279,
     "status": "ok",
     "timestamp": 1709761285751,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "Yooovwdos0Zd",
    "outputId": "e6988b65-1652-4820-fc33-a00575bd5290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28219/28219 [==============================] - 217s 8ms/step - loss: 0.0379\n",
      "Validation Loss: 0.03788694366812706\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation data\n",
    "val_loss = model.evaluate([input_sequences_padded_shuffled, output_sequences_padded_shuffled], output_sequences_padded_shuffled)\n",
    "print('Validation Loss:', val_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8_1xJmJRt8ax",
   "metadata": {
    "id": "8_1xJmJRt8ax"
   },
   "source": [
    "It seems like my validation loss is 0.0379. This value indicates how well my model is performing on the validation data. A lower validation loss generally indicates better performance. Since my final loss is quite low, it suggests that the model is performing well on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SsBXSm-b0WLX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1709763035100,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "SsBXSm-b0WLX",
    "outputId": "e222e46b-25b4-492d-c625-9ce10c321f21",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Input: [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Expected Output: [   4    1 4283   16 8474  627 2288    2    5    6    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Generated Output: [4, 1, 4525, 16, 3020, 627, 1684, 2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Input: [   3    4  989  535   20    7 4673    8 5317    7  752    1   21 1817\n",
      "   84    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [642   2   5   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Generated Output: [642, 2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Input: [3 4 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Expected Output: [5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Generated Output: [5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Input: [   3    4    2   10  133 7264    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [ 9 25  1 25  9  2  5  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "Generated Output: [9, 25, 1, 25, 9, 2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Input: [   3    4  106   73 3184   51   99  346   51   71   85  109    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [108 112 104   2   5   6   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Generated Output: [108, 112, 104, 2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Input: [   3    4 2948   79   12    7  209    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [164  14   7 202 105 404 364  19 127  34   7 282 105  17 111   2   5   6\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Generated Output: [164, 14, 7, 202, 105, 404, 364, 19, 127, 34, 7, 282, 105, 17, 111, 2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Input: [   3    4  878   70   29 3499  284 7239 6285 2461  281 2825   29 3112\n",
      " 1645    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [2034    2    5    6    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Generated Output: [2034, 2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Input: [   3    4  149   12    1   36  808 2793   15    7    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [ 13 105 369  12   2   5   6   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Generated Output: [13, 105, 369, 12, 2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Input: [   3    4 2023 5748   46  987 5749  130    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [1245  433  284  398  178  457  477  395 5750  116 5751  107 5752 5753\n",
      "    2    5    6    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Generated Output: [1245, 433, 284, 398, 178, 457, 477, 395, 5750, 116, 5751, 107, 5750, 5753, 2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Input: [  3   4 185   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Expected Output: [  49   50    7    1    1  158   32  812 7477  204  281 3323   30    2\n",
      "    5    6    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Generated Output: [49, 50, 7, 1, 1, 158, 32, 812, 18367, 204, 281, 2057, 30, 2, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate sample outputs using the trained model\n",
    "sample_outputs = model.predict([input_sequences_padded_shuffled[:10], output_sequences_padded_shuffled[:10]])\n",
    "\n",
    "# Convert the output probabilities into actual words by sampling\n",
    "def sample_word(probabilities, temperature=1.0):\n",
    "    probabilities = np.asarray(probabilities).astype('float64')\n",
    "    log_probabilities = np.log(probabilities) / temperature\n",
    "    exp_probabilities = np.exp(log_probabilities)\n",
    "    probabilities = exp_probabilities / np.sum(exp_probabilities)\n",
    "    sampled_index = np.argmax(np.random.multinomial(1, probabilities, 1))\n",
    "    return sampled_index\n",
    "\n",
    "# Print the sample outputs\n",
    "for i, output_probs in enumerate(sample_outputs):\n",
    "    input_seq = input_sequences_padded_shuffled[i]\n",
    "    expected_output_seq = output_sequences_padded_shuffled[i]\n",
    "\n",
    "    # Convert output probabilities to words\n",
    "    generated_output_seq = [sample_word(output_probs[j]) for j in range(len(output_probs))]\n",
    "\n",
    "    # Print the sequences\n",
    "    print(\"Input:\", input_seq)\n",
    "    print(\"Expected Output:\", expected_output_seq)\n",
    "    print(\"Generated Output:\", generated_output_seq)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca26dc",
   "metadata": {
    "id": "2Dnmx6F35Fso"
   },
   "source": [
    "I generated a sample outputs using the trained model for the first 10 input sequences. Each input sequence is fed into the model, and the output probabilities are obtained using the 'predict' function. Then, the output probabilities are converted into actual words by sampling from the probability distribution.\n",
    "\n",
    "For each input sequence, the I got:\n",
    "- The input sequence.\n",
    "- The expected output sequence.\n",
    "- The generated output sequence obtained by sampling from the output probabilities.\n",
    "\n",
    "The generated output sequences represent the model's predictions for each input sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SNwlUSc_5GII",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1709764277371,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "SNwlUSc_5GII",
    "outputId": "a93f630a-4808-4901-8e74-29711ebba311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "Input: [3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Expected Output: [   4    1 4283   16 8474  627 2288    2    5    6    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Generated Output: [   4    1 7505   16 6705  627 2288    2    5    6    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "\n",
      "Input: [   3    4  989  535   20    7 4673    8 5317    7  752    1   21 1817\n",
      "   84    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [642   2   5   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Generated Output: [642   2   5   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "Input: [3 4 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Expected Output: [5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Generated Output: [5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Input: [   3    4    2   10  133 7264    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [ 9 25  1 25  9  2  5  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "Generated Output: [ 9 25  1 25  9  2  5  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "\n",
      "Input: [   3    4  106   73 3184   51   99  346   51   71   85  109    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [108 112 104   2   5   6   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Generated Output: [108 112 104   2   5   6   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "Input: [   3    4 2948   79   12    7  209    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [164  14   7 202 105 404 364  19 127  34   7 282 105  17 111   2   5   6\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Generated Output: [164  14   7 202 105 404 364  19 127  34   7 282 105  17 111   2   5   6\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "Input: [   3    4  878   70   29 3499  284 7239 6285 2461  281 2825   29 3112\n",
      " 1645    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [2034    2    5    6    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Generated Output: [2034    2    5    6    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "\n",
      "Input: [   3    4  149   12    1   36  808 2793   15    7    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [ 13 105 369  12   2   5   6   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Generated Output: [ 13 105 369  12   2   5   6   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "Input: [   3    4 2023 5748   46  987 5749  130    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Expected Output: [1245  433  284  398  178  457  477  395 5750  116 5751  107 5752 5753\n",
      "    2    5    6    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Generated Output: [1245  433  284  398  178  457  477  395 5750  116 5751  107 7866 5753\n",
      "    2    5    6    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "\n",
      "Input: [  3   4 185   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "Expected Output: [  49   50    7    1    1  158   32  812 7477  204  281 3323   30    2\n",
      "    5    6    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Generated Output: [  49   50    7    1    1  158   32  812 9718  204  281 1730   30    2\n",
      "    5    6    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "\n",
      "Sequence Accuracy: 70.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate sample outputs using the trained model\n",
    "sample_outputs = model.predict([input_sequences_padded_shuffled[:10], output_sequences_padded_shuffled[:10]])\n",
    "\n",
    "# Convert the output probabilities\n",
    "def sample_word(probabilities, temperature=1.0):\n",
    "    probabilities = np.asarray(probabilities).astype('float64')\n",
    "    log_probabilities = np.log(probabilities) / temperature\n",
    "    exp_probabilities = np.exp(log_probabilities)\n",
    "    probabilities = exp_probabilities / np.sum(exp_probabilities)\n",
    "    sampled_index = np.argmax(np.random.multinomial(1, probabilities, 1))\n",
    "    return sampled_index\n",
    "\n",
    "# Initialize accuracy counter\n",
    "correct_sequences = 0\n",
    "\n",
    "# Print the sample outputs and calculate accuracy\n",
    "for i, output_probs in enumerate(sample_outputs):\n",
    "    input_seq = input_sequences_padded_shuffled[i]\n",
    "    expected_output_seq = output_sequences_padded_shuffled[i]\n",
    "\n",
    "    # Convert output probabilities to words\n",
    "    generated_output_seq = np.array([sample_word(output_probs[j]) for j in range(len(output_probs))])\n",
    "\n",
    "    # Check if generated output matches expected output\n",
    "    if np.array_equal(generated_output_seq, expected_output_seq):\n",
    "        correct_sequences += 1\n",
    "\n",
    "    # Print the sequences\n",
    "    print(\"Input:\", input_seq)\n",
    "    print(\"Expected Output:\", expected_output_seq)\n",
    "    print(\"Generated Output:\", generated_output_seq)\n",
    "    print()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (correct_sequences / len(sample_outputs)) * 100\n",
    "print(\"Sequence Accuracy: {:.2f}%\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n4DF5zKB5Xw_",
   "metadata": {
    "id": "n4DF5zKB5Xw_"
   },
   "source": [
    "Based on the provided outputs, the sequence accuracy is calculated to be 70.00%. This means that out of the 10 generated sequences, 7 of them match the expected output sequences exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed8247",
   "metadata": {},
   "source": [
    "#### Evaluation using Bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fly3DdMj5hH2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1154,
     "status": "ok",
     "timestamp": 1709765224502,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "Fly3DdMj5hH2",
    "outputId": "0cac46f4-465d-4e93-ccc3-00b652c1ca32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Generate sample outputs using the trained model\n",
    "sample_outputs = model.predict([input_sequences_padded_shuffled[:10], output_sequences_padded_shuffled[:10]])\n",
    "\n",
    "# Convert the output sequences and reference sequences into text\n",
    "generated_texts = []\n",
    "reference_texts = []\n",
    "for i, output_probs in enumerate(sample_outputs):\n",
    "    generated_text = ' '.join([str(sample_word(output_probs[j])) for j in range(len(output_probs))])\n",
    "    generated_texts.append(generated_text)\n",
    "    reference_text = ' '.join([str(word) for word in output_sequences_padded_shuffled[i]])\n",
    "    reference_texts.append(reference_text)\n",
    "\n",
    "# Tokenize the generated output sequences and reference sequences\n",
    "tokenized_generated_texts = [text.split() for text in generated_texts]\n",
    "tokenized_reference_texts = [text.split() for text in reference_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cvq6QqJO5hKn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1709765252167,
     "user": {
      "displayName": "Beth",
      "userId": "02722972246676483817"
     },
     "user_tz": 420
    },
    "id": "Cvq6QqJO5hKn",
    "outputId": "09565b05-704a-47a4-a190-39ee6d379c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.9546837542095412\n"
     ]
    }
   ],
   "source": [
    "# Calculate BLEU score\n",
    "bleu_scores = [sentence_bleu([reference], hypothesis) for reference, hypothesis in zip(tokenized_reference_texts, tokenized_generated_texts)]\n",
    "\n",
    "# Calculate average BLEU score\n",
    "average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "print(\"Average BLEU Score:\", average_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c2ca2",
   "metadata": {},
   "source": [
    "I calculated the BLEU score for the generated output sequences compared to the reference sequences. I first converted the output sequences and reference sequences into text format and tokenizes them. Then, I computed the BLEU score for each pair of reference and generated sequences using the sentence_bleu function from the NLTK library. Finally, I calculated the average BLEU score across all the sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wgQkA2rv9CWY",
   "metadata": {
    "id": "wgQkA2rv9CWY"
   },
   "source": [
    "I got a BLEU score of approximately 0.954, which indicates that my model's generated sequences are very close to the reference sequences on average, with 1.0 being a perfect match. This suggests that my model performs very well in terms of similarity to the reference sequences.\n",
    "\n",
    "Therefore, my model seems to be performing excellently in generating sequences that closely resemble the expected outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ec357b",
   "metadata": {
    "id": "35303f8c"
   },
   "source": [
    "# ....................End of Code............."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404d134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1dz1DWFOZbfqk7aLfprE72VxC0_6KzSPn",
     "timestamp": 1709765381989
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
